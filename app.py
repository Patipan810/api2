import os
import base64
import json
import logging
import requests
from datetime import datetime
from typing import Dict, List

import pandas as pd
import numpy as np
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from google.oauth2.service_account import Credentials
import gspread
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(level=logging.DEBUG)

app = FastAPI()

# ‚úÖ ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://itbit0267.cpkkuhost.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ URL ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GitHub
GITHUB_FILES = {
    "Respon.xlsx": "https://raw.githubusercontent.com/USERNAME/REPO/BRANCH/Respon.xlsx",
    "Weight.xlsx": "https://raw.githubusercontent.com/USERNAME/REPO/BRANCH/Weight.xlsx",
    "BranchID.Name.xlsx": "https://raw.githubusercontent.com/USERNAME/REPO/BRANCH/BranchID.Name.xlsx"
}

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GitHub
def download_file(url: str, filename: str):
    response = requests.get(url)
    if response.status_code == 200:
        with open(filename, "wb") as f:
            f.write(response.content)
        logging.debug(f"‚úÖ Downloaded {filename} successfully.")
    else:
        logging.error(f"‚ùå Failed to download {filename} from GitHub")
        raise HTTPException(status_code=500, detail=f"Failed to download {filename} from GitHub")

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .xlsx
def load_data():
    try:
        for filename, url in GITHUB_FILES.items():
            if not os.path.exists(filename):
                logging.debug(f"üìÇ Downloading {filename} from {url}")
                download_file(url, filename)
        
        df = pd.read_excel("Respon.xlsx")
        weight = pd.read_excel("Weight.xlsx")
        branch_data = pd.read_excel("BranchID.Name.xlsx")
        
        if df.empty or weight.empty or branch_data.empty:
            logging.error("‚ùå One or more dataframes are empty!")
            raise HTTPException(status_code=500, detail="One or more data files are empty!")
        
        df = df.drop(['Timestamp', 'User'], axis=1, errors='ignore')
        label_encoder = LabelEncoder()
        df['Course'] = label_encoder.fit_transform(df['Course'].astype(str))
        
        for column in df.select_dtypes(include=['object']).columns:
            df[column] = LabelEncoder().fit_transform(df[column].astype(str))
        
        score_data = df.drop(['Course', 'Branch'], axis=1, errors='ignore')
        return df, weight, branch_data, score_data, label_encoder
    except Exception as e:
        logging.error(f"‚ùå Error reading Excel files: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error reading Excel files: {str(e)}")

# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets
def connect_google_sheets():
    try:
        logging.debug("üîë Connecting to Google Sheets...")
        google_credentials_base64 = os.getenv('GOOGLE_CREDENTIALS')

        if not google_credentials_base64:
            logging.error("‚ùå GOOGLE_CREDENTIALS is missing!")
            raise HTTPException(status_code=500, detail="Google Sheets credentials not found!")

        google_credentials_json = base64.b64decode(google_credentials_base64)
        credentials_dict = json.loads(google_credentials_json)
        creds = Credentials.from_service_account_info(credentials_dict)
        client = gspread.authorize(creds)
        sheet = client.open("Data_project_like_course_branch").sheet1
        logging.debug("‚úÖ Connected to Google Sheets successfully!")
        return sheet
    except Exception as e:
        logging.error(f"‚ùå Google Sheets connection error: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Google Sheets connection error: {str(e)}")
        
# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≤‡∏Ç‡∏≤
def get_recommended_branches(courses: List[str], subject_scores: list, branch_data, Weight) -> List[str]:
    logging.debug(f"? ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞: {courses}")
    logging.debug(f"? ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {subject_scores}")
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    branch_data['Course'] = branch_data['Course'].astype(str)
    courses = [str(course) for course in courses]
    
    # ‡∏´‡∏≤ branch IDs ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    relevant_branches = branch_data[branch_data['Course'].isin(courses)]
    logging.debug(f"? ‡∏û‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {len(relevant_branches)} ‡∏™‡∏≤‡∏Ç‡∏≤")
    
    if relevant_branches.empty:
        logging.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
        return []
    
    all_branch_ids = relevant_branches['BranchID'].values
    logging.debug(f"? BranchID ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {all_branch_ids}")
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏° branch IDs
    relevant_weights = Weight[Weight['BranchID'].isin(all_branch_ids)]
    logging.debug(f"? ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {len(relevant_weights)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    if relevant_weights.empty:
        logging.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        return []
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á
    user_scores_array = np.array(subject_scores).reshape(1, -1)
    filtered_weight = relevant_weights.drop(columns=['BranchID']).fillna(0)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    logging.debug(f"? ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {user_scores_array.shape}")
    logging.debug(f"? ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å: {filtered_weight.shape}")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if user_scores_array.shape[1] != filtered_weight.shape[1]:
        logging.error(f"‚ùå ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô: user_scores={user_scores_array.shape[1]}, filtered_weight={filtered_weight.shape[1]}")
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô (‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤)
        min_cols = min(user_scores_array.shape[1], filtered_weight.shape[1])
        logging.warning(f"‚ö†Ô∏è ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ {min_cols} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
        user_scores_array = user_scores_array[:, :min_cols]
        filtered_weight = filtered_weight.iloc[:, :min_cols]
    
    cosine_similarities = cosine_similarity(user_scores_array, filtered_weight)[0]
    logging.debug(f"? ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ: {cosine_similarities}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    results = pd.DataFrame({
        'BranchID': relevant_weights['BranchID'].values,
        'Similarity': cosine_similarities
    })
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0 ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
    top_branches = results[results['Similarity'] > 0].nlargest(10, 'Similarity')
    logging.debug(f"? ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {top_branches.to_dict()}")
    
    recommended_branches = []
    for _, row in top_branches.iterrows():
        branch_info = branch_data.loc[branch_data['BranchID'] == row['BranchID']]
        if not branch_info.empty:
            branch_name = branch_info['Branch'].values[0]
            similarity = float(row['Similarity'] * 100)
            recommended_branches.append(f"{branch_name} (‡∏Ñ‡πà‡∏≤ Similarity: {similarity:.2f}%)")
    
    return recommended_branches
# ‚úÖ API ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
@app.post("/api/recommend")
async def recommend(payload: Dict[str, Dict[str, str]]):
    try:
        logging.debug(f"üì• Received Payload: {payload}")
        df, weight, branch_data, score_data, label_encoder = load_data()
        personality_values = [int(payload['personality_answers'][key]) for key in sorted(payload['personality_answers'])]
        subject_values = [float(payload['scores'][key]) for key in sorted(payload['scores'])]
        similarity_scores = cosine_similarity([personality_values], score_data)[0]
        recommended_courses = list(label_encoder.inverse_transform(df.iloc[np.argsort(similarity_scores)[-5:][::-1]]['Course']))
        logging.debug(f"üéì Recommended Courses: {recommended_courses}")
        recommended_branches = get_recommended_branches(recommended_courses, subject_values, branch_data, weight)
        logging.debug(f"üè´ Recommended Branches: {recommended_branches}")
        return {
            "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥": {
                "‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å": [{"name": course} for course in recommended_courses],
                "‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å": recommended_branches or ["‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì"]
            }
        }
    except Exception as e:
        logging.error(f"‚ùå Error in /api/recommend: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ‚úÖ API ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
@app.post("/api/save-liked-result")
async def save_liked_result(data: Dict):
    try:
        sheet = connect_google_sheets()
        new_data = [datetime.now().strftime("%Y-%m-%d %H:%M:%S")] + list(data['personalityAnswers'].values()) + list(data['scores'].values()) + [c['name'] for c in data['recommendations']['‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å']] + data['recommendations']['‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å']
        sheet.append_row(new_data)
        return {"success": True, "message": "Data saved successfully"}
    except Exception as e:
        logging.error(f"‚ùå Error saving to Google Sheets: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
